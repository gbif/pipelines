alaNameMatch:
  wsUrl: http://${alanm.host}:${alanm.port}
  timeoutSec: 70

collectory:
  wsUrl: ${collectory.url}
  timeoutSec: 70

sds:
  wsUrl: http://${sds.host}:${sds.port}
  timeoutSec: 70

speciesListService:
  wsUrl: http://${speciesListService.host}:${speciesListService.port}
  timeoutSec: 70

geocodeConfig:
  country:
    path: "/tmp/pipelines-shp/political"
    field: ISO_A2
    source: "http://www.naturalearthdata.com"
    intersectBuffer:  0.135
    intersectMapping:
      CX: AU
      CC: AU
      HM: AU
      NF: AU
  eez:
    path: "/tmp/pipelines-shp/eez"
    field: ISO2
    source: "http://www.naturalearthdata.com"
    intersectBuffer: 0.135
  stateProvince:
    path: "/tmp/pipelines-shp/cw_state_poly"
    field: FEATURE
    source: "http://vliz.be/vmdcdata/marbound/"
    intersectBuffer: 0.135
  biome:
    path: "/tmp/pipelines-shp/gadm0"
    field: FEATURE

general:
  targetPath: /data/pipelines-data
  attempt: 1
  hdfsSiteConfig: ""
  coreSiteConfig: ""

dwca-avro:
  runner: SparkRunner
  metaFileName: dwca-metrics.yml
  inputPath: /data/biocache-load/{datasetId}

interpret:
  default:
    interpretationTypes: ALL
    inputPath: /data/pipelines-data/{datasetId}/1/verbatim.avro
    metaFileName: interpretation-metrics.yml
    useExtendedRecordId: true
  spark-cluster:
    name: interpret {datasetId}
    appName: Interpretation for {datasetId}
    runner: SparkRunner
  spark-embedded:
    runner: SparkRunner

export-latlng:
  inputPath: /data/pipelines-data
  runner: SparkRunner
  appName: Lat Long export for {datasetId}

sample:
  default:
  cluster:
  avro-cluster:
  embedded:
    appName: SamplingToAvro indexing for {datasetId}
    runner: SparkRunner
    inputPath: /data/pipelines-data
    metaFileName: indexing-metrics.yml

# LayerCrawler specific configuration
layerCrawler:
  # baseUrl: https://spatial.your-l-a.site/ws/
  baseUrl: https://sampling.ala.org.au/sampling-service/
  batchSize: 25000
  batchStatusSleepTime: 1000
  downloadRetries: 5

migrate-uuids:
  default:
    runner: SparkRunner
    metaFileName: uuid-metrics.yml
    targetPath: /data/pipelines-data
    inputPath: /data/pipelines-data/occ_uuid.csv
  test:
    runner: DirectRunner

uuid:
  embedded:
    appName: UUID minting for {datasetId}
    runner: SparkRunner
    inputPath: /data/pipelines-data
    metaFileName: uuid-metrics.yml

index:
  default:
    inputPath: /data/pipelines-data
    metaFileName: indexing-metrics.yml
  java:
    includeSampling: true
    zkHost: ${solr8.zk.host}:${solr8.zk.port}
    solrCollection: biocache
  spark-cluster:
  spark-embedded:
    appName: SOLR indexing for {datasetId}
    runner: SparkRunner
    zkHost: ${solr8.zk.host}:${solr8.zk.port}
    solrCollection: biocache
    includeSampling: true

test:
  zkHost: ${solr8.zk.host}:${solr8.zk.port}
  solrAdminHost: ${solr8.http.host}:${solr8.http.port}

root-test: 1
