# Deployment specific configuration for locql machine using a locally installed HDFS.
# This file should be copied over `la-pipelines-local.yaml` when deployed
# so that it is used by the scripts.
#
run:
    # where to run: local, spark-embedded or spark-cluster
    platform: local
    local:
        # jar: we get the jar from our dev or production environment
        sparkTmp: /data/spark-tmp
        dwcaTmp: /data/dwca-tmp
        dwcaImportDir: hdfs://localhost:8020/dwca-exports
        sparkMaster: ""
    spark-embedded:
        # jar: we get the jar from our dev or production environment
        sparkTmp: /data/spark-tmp
        dwcaTmp: /data/dwca-tmp
        dwcaImportDir: hdfs://localhost:8020/dwca-exports
        sparkMaster: ""
    spark-cluster:
        jar: /efs-mount-point/la-pipelines.jar
        dwcaImportDir: hdfs://localhost:8020/dwca-exports
        sparkTmp: /data/spark-tmp
        sparkMaster: spark://localhost:7077

collectory:
    wsUrl: https://collections.ala.org.au
    timeoutSec: 70
    httpHeaders:
        Authorization: << ADD ME >>

imageService:
    wsUrl: https://images-dev.ala.org.au
    httpHeaders:
        apiKey: << ADD ME >>

general:
    attempt: 1
    hdfsSiteConfig: /usr/local/Cellar/hadoop/3.2.1_1/libexec/etc/hadoop/hdfs-site.xml
    coreSiteConfig: /usr/local/Cellar/hadoop/3.2.1_1/libexec/etc/hadoop/core-site.xml
    inputPath: hdfs://localhost:8020/pipelines-data
    targetPath: hdfs://localhost:8020/pipelines-data
dwca-avro:
    inputPath: hdfs://localhost:8020/dwca-exports/{datasetId}/{datasetId}.zip
    tempLocation: /data/spark-tmp/dwca-avro/{datasetId}
interpret:
    defaultDateFormat: DMYT,DMY
    inputPath: hdfs://localhost:8020/pipelines-data/{datasetId}/1/verbatim.avro
dataset-validated-dump:
    inputPath: hdfs://localhost:8020/pipelines-data
dataset-count-dump:
    inputPath: hdfs://localhost:8020/pipelines-data
dataset-archive-list:
    inputPath: hdfs://localhost:8020/dwca-exports/
images:
    inputPath: hdfs://localhost:8020/pipelines-data
    targetPath: hdfs://localhost:8020/pipelines-data
export-latlng:
    inputPath: hdfs://localhost:8020/pipelines-data
uuid:
    inputPath: hdfs://localhost:8020/pipelines-data
validation-report:
    inputPath: hdfs://localhost:8020/pipelines-data
    checkSolr: false
sample-avro:
    inputPath: hdfs://localhost:8020/pipelines-data
index:
    inputPath: hdfs://localhost:8020/pipelines-data
    zkHost: localhost:9983
outlier:
    inputPath: hdfs://localhost:8020/pipelines-data
    targetPath: hdfs://localhost:8020/pipelines-outlier

