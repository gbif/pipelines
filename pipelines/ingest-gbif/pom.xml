<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>

  <parent>
    <groupId>org.gbif.pipelines</groupId>
    <artifactId>pipelines</artifactId>
    <version>2.0.6-SNAPSHOT</version>
    <relativePath>../pom.xml</relativePath>
  </parent>

  <artifactId>ingest-gbif</artifactId>
  <packaging>jar</packaging>

  <name>Pipelines :: Pipelines :: Ingest-GBIF</name>
  <description>Base Apache Beam pipelines for ingestion biodiversity data</description>

  <build>
    <plugins>
      <!-- Shade the project into an uber jar to send to Spark -->
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-shade-plugin</artifactId>
        <configuration>
          <createDependencyReducedPom>false</createDependencyReducedPom>
          <filters>
            <filter>
              <artifact>*:*</artifact>
              <excludes>
                <exclude>META-INF/*.SF</exclude>
                <exclude>META-INF/*.DSA</exclude>
                <exclude>META-INF/*.RSA</exclude>
              </excludes>
            </filter>
          </filters>
        </configuration>
        <executions>
          <execution>
            <phase>package</phase>
            <goals>
              <goal>shade</goal>
            </goals>
            <configuration>
              <shadedArtifactAttached>true</shadedArtifactAttached>
              <shadedClassifierName>shaded</shadedClassifierName>
              <transformers>
                <transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer" />
              </transformers>
              <relocations>
                <!-- Transient from core: conflicts with Beam on Spark -->
                <relocation>
                  <pattern>okio</pattern>
                  <shadedPattern>o113.okio</shadedPattern>
                </relocation>

                <relocation>
                  <pattern>retrofit2</pattern>
                  <shadedPattern>gbif.retrofit2</shadedPattern>
                </relocation>

                <!-- Transient from elastic search Beam: conflicts with hive-jdbc-1.1.0-cdh5.12.1-standalone.jar -->
                <relocation>
                  <pattern>org.apache.http</pattern>
                  <shadedPattern>hc45.org.apache.http</shadedPattern>
                </relocation>

                <!-- Transient from core: conflicts with Hadoop on Spark -->
                <relocation>
                  <pattern>org.hsqldb</pattern>
                  <shadedPattern>gbif.hsqldb</shadedPattern>
                </relocation>

              </relocations>
            </configuration>
          </execution>
        </executions>
      </plugin>
    </plugins>
  </build>

  <dependencies>

    <!-- This project -->
    <dependency>
      <groupId>org.gbif.pipelines</groupId>
      <artifactId>models</artifactId>
    </dependency>
    <dependency>
      <groupId>org.gbif.pipelines</groupId>
      <artifactId>beam-common</artifactId>
    </dependency>
    <dependency>
      <groupId>org.gbif.pipelines</groupId>
      <artifactId>ingest-transforms</artifactId>
    </dependency>
    <dependency>
      <groupId>org.gbif.pipelines</groupId>
      <artifactId>elasticsearch-tools</artifactId>
    </dependency>

    <!-- Beam -->
    <dependency>
      <groupId>org.apache.beam</groupId>
      <artifactId>beam-sdks-java-core</artifactId>
    </dependency>
    <dependency>
      <groupId>org.apache.beam</groupId>
      <artifactId>beam-runners-spark</artifactId>
    </dependency>
    <dependency>
      <groupId>org.apache.beam</groupId>
      <artifactId>beam-sdks-java-io-hadoop-file-system</artifactId>
    </dependency>
    <dependency>
      <groupId>org.apache.beam</groupId>
      <artifactId>beam-sdks-java-io-elasticsearch</artifactId>
    </dependency>

    <!-- Hadoop -->
    <dependency>
      <groupId>org.apache.hadoop</groupId>
      <artifactId>hadoop-common</artifactId>
    </dependency>

    <!-- Common -->
    <dependency>
      <groupId>org.apache.avro</groupId>
      <artifactId>avro</artifactId>
    </dependency>

    <!-- Utils -->
    <dependency>
      <groupId>com.google.guava</groupId>
      <artifactId>guava</artifactId>
    </dependency>

    <!-- Logging -->
    <dependency>
      <groupId>org.slf4j</groupId>
      <artifactId>slf4j-api</artifactId>
    </dependency>
    <dependency>
      <groupId>ch.qos.logback</groupId>
      <artifactId>logback-classic</artifactId>
    </dependency>
    <dependency>
      <groupId>net.logstash.logback</groupId>
      <artifactId>logstash-logback-encoder</artifactId>
    </dependency>

    <!-- Json -->
    <dependency>
      <groupId>com.fasterxml.jackson.core</groupId>
      <artifactId>jackson-annotations</artifactId>
    </dependency>
    <dependency>
      <groupId>com.fasterxml.jackson.core</groupId>
      <artifactId>jackson-databind</artifactId>
    </dependency>

  </dependencies>


</project>